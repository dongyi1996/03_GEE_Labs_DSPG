{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "We've gone over indices to highlight unique characteristics in our imagery by utilizing the bands outside of the visible spectrum. \n",
    "\n",
    "Linear transforms are linear combinations of input pixel values. These can result from a variety of different strategies, but a common theme is that pixels are treated as arrays of band values, and we can use these arrays to create weighted values for specific purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasseled cap (TC)\n",
    "\n",
    "Based on observations of agricultural land covers in the NIR-red spectral space, [Kauth and Thomas (1976)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.461.6381&rep=rep1&type=pdf) devised a [rotational transform](https://en.wikipedia.org/wiki/Change_of_basis) of the form \n",
    "\n",
    "$$p_1 = R^T p_0$$\n",
    "\n",
    "where: \n",
    "\n",
    "1. **$p_0$** is the original pixel vector (a stack of the *p* band values as an [Array](https://developers.google.com/earth-engine/arrays_intro)) \n",
    "\n",
    "2. **$p_1$** is the rotated pixel\n",
    "\n",
    "3. **R** is an [orthonormal basis](https://en.wikipedia.org/wiki/Orthonormal_basis) of the new space (inverse of $R^T$). Kauth and Thomas found **R** by defining the first axis of their transformed space to be parallel to the soil line in the following chart, then used the [Gram-Schmidt process](https://en.wikipedia.org/wiki/Gram–Schmidt_process) to find the other basis vectors.\n",
    "\n",
    "![Tassled Cap](https://github.com/ghidora77/03_GEE_Labs_DSPG/blob/main/im/im_03_07.png?raw=true)\n",
    "\n",
    "Assuming that **R** is available, one way to implement this rotation in Earth Engine is with arrays. Specifically, make an array of TC coefficients. Since these coefficients are for the TM sensor, get a less cloudy Landsat 5 scene. To do the matrix multiplication, first convert the input image from a multi-band image to an array image in which each pixel position stores an array. Do the matrix multiplication, then convert back to a multi-band image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geemap\n",
    "\n",
    "import ee, geemap, pprint, folium\n",
    "#ee.Authenticate()\n",
    "\n",
    "def build_map(lat, lon, zoom, vizParams, image, name):\n",
    "    map = geemap.Map(center = [lat, lon], zoom = zoom)\n",
    "    map.addLayer(image, vizParams, name)\n",
    "    return map\n",
    "\n",
    "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
    "  map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
    "  folium.raster_layers.TileLayer(\n",
    "      tiles=map_id_dict['tile_fetcher'].url_format,\n",
    "      attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "      name=name,\n",
    "      overlay=True,\n",
    "      control=True\n",
    "  ).add_to(self)\n",
    "\n",
    "# Initialize the Earth Engine module.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 39.19; lon = -106.81; \n",
    "zoom = 11\n",
    "image_collection_name = \"LANDSAT/LT05/C01/T1_TOA\"\n",
    "date_start = '2008-06-01'\n",
    "date_end = '2008-12-01'\n",
    "name = 'Snow'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "coefficients = ee.Array([    \n",
    "  [0.3037, 0.2793, 0.4743, 0.5585, 0.5082, 0.1863],    \n",
    "  [-0.2848, -0.2435, -0.5436, 0.7243, 0.0840, -0.1800],\n",
    "  [0.1509, 0.1973, 0.3279, 0.3406, -0.7112, -0.4572],\n",
    "  [-0.8242, 0.0849, 0.4392, -0.0580, 0.2012, -0.2768],\n",
    "  [-0.3280, 0.0549, 0.1075, 0.1855, -0.4357, 0.8085],\n",
    "  [0.1084, -0.9022, 0.4120, 0.0573, -0.0251, 0.0238]\n",
    "]);  \n",
    "\n",
    "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527d19acf7b842b29c91a181d4ea4492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[39.19, -106.81], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make an Array Image,  with a 1-D Array per pixel.\n",
    "\n",
    "arrayImage1D =  image.select(bands).toArray();\n",
    "# Make an Array Image  with a 2-D Array per pixel, 6x1.\n",
    "arrayImage2D = arrayImage1D.toArray(1);  \n",
    "componentsImage = (ee.Image(coefficients).matrixMultiply(arrayImage2D)\n",
    "    # Get rid of the extra  dimensions.\n",
    "        .arrayProject([0])  \n",
    "    # Get a multi-band image  with TC-named bands.  \n",
    "        .arrayFlatten(\n",
    "          [['brightness', 'greenness', 'wetness', 'fourth', 'fifth', 'sixth']]\n",
    "        ))\n",
    "\n",
    "vizParams = {\n",
    "  'bands': ['brightness', 'greenness', 'wetness'],\n",
    "  'min': -0.1, \n",
    "    'max': [0.5,  0.1, 0.1]\n",
    "}\n",
    "\n",
    "map8 = build_map(lat, lon, zoom, vizParams, componentsImage, 'TC components')\n",
    "map8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis (PCA)\n",
    "\n",
    "Like the Tasseled Cap transform, the [PCA transform](https://en.wikipedia.org/wiki/Principal_component_analysis) is a rotational transform in which the new basis is orthonormal, but the axes are determined from statistics of the input image, rather than empirical data. Specifically, the new basis is the [eigenvector](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors) of the image's [variance-covariance matrix](https://en.wikipedia.org/wiki/Covariance_matrix). As a result, the principal components are uncorrelated. To demonstrate, use the Landsat 8 image converted to an array image. Use the `reduceRegion()` [method](https://developers.google.com/earth-engine/reducers_reduce_region) to compute statistics (band covariances) for the image.\n",
    "\n",
    "A [*reducer*](https://developers.google.com/earth-engine/reducers_intro) is an object that tells Earth Engine what statistic to compute. Note that the result of the reduction is an object with one property, an array, that stores the covariance matrix. The next step is to compute the eigenvectors and eigenvalues of that covariance matrix. Since the eigenvalues are appended to the eigenvectors, slice the two apart and discard the eigenvectors. Perform the matrix multiplication, as with the TC components. Finally, convert back to a multi-band image and display the first PC.\n",
    "\n",
    "Use the [layer manager](https://developers.google.com/earth-engine/playground#layer-manager) to stretch the result appropriately. What do you observe? Try displaying some of the other principal components. The image parameters in the code chunk below are built specifically for Principal Component 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12daaf5b47bb4106b892f5d7d0aeba1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.22, -80.42], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(childr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lat = 37.22; lon = -80.42; \n",
    "zoom = 11\n",
    "image_collection_name = \"LANDSAT/LC08/C01/T1_TOA\"\n",
    "date_start = '2013-11-17'\n",
    "date_end = '2014-03-27'\n",
    "name = 'PCA'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "\n",
    "bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11']\n",
    "\n",
    "arrayImage =  image.select(bands).toArray();  \n",
    "covar = arrayImage.reduceRegion(\n",
    "  reducer = ee.Reducer.covariance(),\n",
    "  maxPixels = 1000000000\n",
    ")\n",
    "\n",
    "covarArray = ee.Array(covar.get('array'));  \n",
    "eigens = covarArray.eigen();  \n",
    "eigenVectors = eigens.slice(1, 1); \n",
    "\n",
    "principalComponents = ee.Image(eigenVectors).matrixMultiply(arrayImage.toArray(1));  \n",
    "pcImage = (principalComponents      \n",
    "                        .arrayProject([0])    \n",
    "    # Make the one band  array image a multi-band image, [] -> image.    \n",
    "                    .arrayFlatten(\n",
    "          [['pc1', 'pc2', 'pc3', 'pc4', 'pc5', 'pc6', 'pc7', 'pc8']]\n",
    "        )); \n",
    "\n",
    "#Customize the visual parameters for PC1\n",
    "vizParams = {\n",
    "  \"opacity\":1,\n",
    "  \"bands\": [\"pc1\"],\n",
    "  \"min\":-420,\n",
    "    \"max\":-400,\n",
    "  \"gamma\":1}\n",
    "\n",
    "map8 = build_map(lat, lon, zoom, vizParams, pcImage.select('pc1'), 'TC components')\n",
    "map8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Unmixing\n",
    "\n",
    "The [linear spectral mixing model](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=974727&tag=1) is based on the assumption that each pixel is a mixture of \"pure\" spectra. The pure spectra, called *endmembers*, are from land cover classes such as water, bare land, vegetation. The goal is to solve the following equation for **f**, the *P*x1 vector of endmember fractions in the pixel:  \n",
    "\n",
    "$$Sf = p$$\n",
    "\n",
    "where **S** is a *B*x*P* matrix in which the columns are *P* pure endmember spectra (known) and **p** is the *B*x1 pixel vector when there are *B* bands (known). In this example, $B= 6$: \n",
    "\n",
    "The first step is to get the endmember spectra, which we can do by computing the mean spectra in polygons around regions of pure land cover. In this example, we will use a location in northern Washington State and use the geometry tools to select homogeneous areas of bare land, vegetation and water.\n",
    "\n",
    "Using the [geometry drawing tools](https://developers.google.com/earth-engine/playground#geometry-tools), make three layers clicking **+ new layer**. In the first layer, digitize a polygon around pure bare land, in the second layer make a polygon of pure vegetation, and in the third layer, make a water polygon. Name the imports `bare`, `water` and, and `vegetation`, respectively. \n",
    "\n",
    "Note: For a starting point, we included some basic polygons but feel free to replace in a region of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 48.11; lon = -123.25; \n",
    "zoom = 11\n",
    "image_collection_name = \"LANDSAT/LC08/C01/T1_TOA\"\n",
    "date_start = '2013-06-17'\n",
    "date_end = '2014-03-27'\n",
    "name = 'PCA'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "# Polygons of bare earth, water and vegetation\n",
    "bare = (\n",
    "    ee.Geometry.Polygon(\n",
    "        [[[-123.2370707334838, 48.1151452657945],\n",
    "          [-123.2370707334838, 48.11351208612645],\n",
    "          [-123.23410957473136, 48.11351208612645],\n",
    "          [-123.23410957473136, 48.1151452657945]]]))\n",
    "water = (\n",
    "    ee.Geometry.Polygon(\n",
    "        [[[-123.2748188020549, 48.12059599002954],\n",
    "          [-123.2748188020549, 48.118074835535865],\n",
    "          [-123.2673086168132, 48.118074835535865],\n",
    "          [-123.2673086168132, 48.12059599002954]]]))\n",
    "vegetation = (\n",
    "    ee.Geometry.Polygon(\n",
    "        [[[-123.27462568300582, 48.11533866992809],\n",
    "          [-123.27462568300582, 48.114163936320416],\n",
    "          [-123.27215805071212, 48.114163936320416],\n",
    "          [-123.27215805071212, 48.11533866992809]]]))\n",
    "unmixImage = image.select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7'])\n",
    "unmixImage = image.select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nvar = (\\nprint(Chart.image.regions(unmixImage, ee.FeatureCollection([\\n    ee.Feature(bare, {label: 'bare'}), \\n    ee.Feature(water, {label: 'water'}),\\n    ee.Feature(vegetation, {label: 'vegetation'})]), \\n  ee.Reducer.mean(), 30, 'label', [0.48, 0.56, 0.65, 0.86, 1.61, 2.2])))\\n  \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Need to update charts \n",
    "\"\"\"\n",
    "var = (\n",
    "print(Chart.image.regions(unmixImage, ee.FeatureCollection([\n",
    "    ee.Feature(bare, {label: 'bare'}), \n",
    "    ee.Feature(water, {label: 'water'}),\n",
    "    ee.Feature(vegetation, {label: 'vegetation'})]), \n",
    "  ee.Reducer.mean(), 30, 'label', [0.48, 0.56, 0.65, 0.86, 1.61, 2.2])))\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Check the polygons you made by charting mean spectra in them using [Chart.image.regions()](https://developers.google.com/earth-engine/charts_image_regions):\n",
    "\n",
    "Your chart should look something like:\n",
    "\n",
    "![Charting Spectra](https://github.com/ghidora77/03_GEE_Labs_DSPG/blob/main/im/im_04_03.png?raw=true)\n",
    "Use the [reduceRegion() method](https://developers.google.com/earth-engine/reducers_reduce_region) to compute mean spectra in the polygons you made. Note that the return value of reduceRegion() is a Dictionary, with reducer output keyed by band name. Get the means as a list by calling `values()`. Each of these three lists represents a mean spectrum vector. Stack the vectors into a 6x3 Array of endmembers by concatenating them along the 1-axis (or columns direction).\n",
    "\n",
    "Turn the 6-band input image into an image in which each pixel is a 1D vector (`toArray()`), then into an image in which each pixel is a 6x1 matrix (`toArray(1)`). Now that the dimensions match, in each pixel, solve the equation for **f**. Finally, convert the result from a 2D array image into a 1D array image (`arrayProject()`), then to a multi-band image (`arrayFlatten()`). The three bands correspond to the estimates of bare, vegetation and water fractions in **f**. Display the result where bare is red, vegetation is green, and water is blue (the `addLayer()` call expects bands in order, RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cf398906e249649d592995d43d69bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[48.11, -123.25], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bareMean = unmixImage.reduceRegion(\n",
    "  ee.Reducer.mean(), bare, 30).values();   \n",
    "waterMean = unmixImage.reduceRegion(\n",
    "  ee.Reducer.mean(), water, 30).values();   \n",
    "vegMean = unmixImage.reduceRegion(\n",
    "  ee.Reducer.mean(), vegetation, 30).values();\n",
    "\n",
    "endmembers = ee.Array.cat([bareMean,  vegMean, waterMean], 1);  \n",
    "arrayImage = unmixImage.toArray().toArray(1);\n",
    "unmixed =  ee.Image(endmembers).matrixSolve(arrayImage);\n",
    "unmixedImage = unmixed.arrayProject([0]).arrayFlatten(\n",
    "          [['bare', 'veg', 'water']]\n",
    "        );\n",
    "\n",
    "map8 = build_map(lat, lon, zoom, {}, unmixedImage, 'unmixedImage')\n",
    "map8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hue-Saturation-Value Transform\n",
    "\n",
    "The Hue-Saturation-Value (HSV) model [is a color transform of the RGB color space](https://en.wikipedia.org/wiki/HSL_and_HSV). Among many other things, it is useful for [pan-sharpening](https://en.wikipedia.org/wiki/Pansharpened_image). This involves converting an RGB to HSV, swapping the panchromatic band for the value (V), then converting back to RGB. For example, using the Landsat 8 scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669ffbe6f5b54aa2ae7515a70e7fbf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.22, -80.42], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(childr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lat = 37.22; lon = -80.42; \n",
    "zoom = 11;\n",
    "image_collection_name = \"LANDSAT/LC08/C01/T1_TOA\"\n",
    "date_start = '2013-06-17'\n",
    "date_end = '2014-03-27'\n",
    "name = 'Hue Saturation'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "\n",
    "# Convert Landsat RGB bands to HSV   \n",
    "hsv = image.select(['B4', 'B3', 'B2']).rgbToHsv();\n",
    "# Convert back to RGB,  swapping the image panchromatic band for the value.\n",
    "rgb = ee.Image.cat([\n",
    "  hsv.select('hue'),\n",
    "  hsv.select('saturation'),\n",
    "  image.select(['B8'])]).hsvToRgb();\n",
    "\n",
    "map8 = build_map(lat, lon, zoom, {'max': 0.4}, rgb, 'hue saturation')\n",
    "map8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Transformation\n",
    "\n",
    "### Linear Filtering\n",
    "\n",
    "In the present context, linear *filtering* (or [convolution](http://www.dspguide.com/ch24/1.htm)) refers to a linear combination of pixel values in a 'neighborhood', or [kernel](https://en.wikipedia.org/wiki/Kernel_(image_processing)), where the weights of the kernel determine the coefficients in the linear combination (for this lab, the terms *kernel* and *filter* are interchangeable.) Filtering an image can be useful for extracting image information at different [spatial frequencies](http://www.dspguide.com/ch24/5.htm) by reducing noise. For this reason, smoothing filters are called *low-pass* filters (they let *low*-frequency data *pass* through) and edge detection filters are called *high-pass* filters. To implement filtering in Earth Engine use [image.convolve()](https://developers.google.com/earth-engine/guides/image_convolutions) with an ee.Kernel for the argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smoothing\n",
    "\n",
    "Smoothing means to convolve an image with a smoothing kernel. \n",
    "\n",
    "A simple smoothing filter is a square kernel with uniform weights that sum to one. Convolving with this kernel sets each pixel to the mean of its neighborhood. Print a square kernel with uniform weights (this is sometimes called a \"pillbox\" or \"boxcar\" filter):\n",
    "\n",
    "Expand the kernel object in the console to see the weights. This kernel is defined by how many pixels it covers (i.e. `radius` is in units of 'pixels'). A kernel with radius defined in 'meters' adjusts its size in pixels, so you can't visualize its weights, but it's more flexible in terms of adapting to inputs of different scale. In the following, use kernels with radius defined in meters except to visualize the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 37.22; lon = -80.42; \n",
    "zoom = 14\n",
    "image_collection_name = \"USDA/NAIP/DOQQ\"\n",
    "date_start = '2013-06-17'\n",
    "date_end = '2017-03-27'\n",
    "name = 'NAIP'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "\n",
    "# Print a uniform kernel to see its weights.\n",
    "# print('A uniform kernel:', ee.Kernel.square(2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kernel Description](https://github.com/ghidora77/03_GEE_Labs_DSPG/blob/main/im/im_03_11.png?raw=true)\n",
    "\n",
    "Define a kernel with 2-meter radius (which corresponds to how many pixels in the NAIP image? Hint: try [projection.nominalScale()](https://developers.google.com/earth-engine/guides/projections)), convolve the image with the kernel and compare the input image with the smoothed image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6476f90be1cd41d487e64f2f61b55608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.22, -80.42], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(childr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a square, uniform kernel.\n",
    "uniformKernel = ee.Kernel.square(\n",
    " radius =  2,\n",
    " units = 'meters',\n",
    ")\n",
    "\n",
    "# Filter the image by convolving with the smoothing filter.\n",
    "smoothed = image.convolve(uniformKernel)\n",
    "vizParams = {\n",
    "  'min': 0.0,\n",
    "  'max': 255,\n",
    "}\n",
    "\n",
    "map9 = build_map(lat, lon, zoom, vizParams, smoothed, 'Smoothed')\n",
    "map9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the image even smoother, try increasing the size of the neighborhood by increasing the pixel radius. to the human eye, the image is blurrier, but in many Machine Learning and Computer Vision algorithms, this process improves our output by reducing noise. \n",
    "\n",
    "\n",
    "A Gaussian kernel can also be used for smoothing. Think of filtering with a Gaussian kernel as computing the weighted average in each pixel's neighborhood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095e7aca838845e18aefc9e9d7ba0c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.22, -80.42], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(childr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print a Gaussian kernel to see its weights.\n",
    "\n",
    "#print('A Gaussian kernel:', ee.Kernel.gaussian(2))\n",
    "\n",
    "# Define a square Gaussian kernel:\n",
    "gaussianKernel = ee.Kernel.gaussian(\n",
    " radius =  2,\n",
    " units = 'meters',\n",
    ")\n",
    "\n",
    "# Filter the image by convolving with the smoothing filter.\n",
    "gaussiansmooth = image.convolve(gaussianKernel)\n",
    "\n",
    "map9 = build_map(lat, lon, zoom, vizParams, gaussiansmooth, 'Smoothed')\n",
    "map9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge Detection\n",
    "\n",
    "Convolving with an edge-detection kernel is used to find rapid changes in values that usually signify the edges of objects in the image data. \n",
    "\n",
    "A classic edge detection kernel is the [Laplacian](https://en.wikipedia.org/wiki/Discrete_Laplace_operator) kernel. Investigate the kernel weights and the image that results from convolving with the Laplacian. Other edge detection kernels include the [Sobel](https://en.wikipedia.org/wiki/Sobel_operator), [Prewitt](https://en.wikipedia.org/wiki/Prewitt_operator) and [Roberts](https://en.wikipedia.org/wiki/Roberts_cross) kernels. [Learn more about additional edge detection methods in Earth Engine](https://developers.google.com/earth-engine/image_edges). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb492aeb0a0d44cd8f06882498152abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.22, -80.42], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(childr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a Laplacian, or edge-detection kernel.\n",
    "laplace = ee.Kernel.laplacian8(normalize= False)\n",
    "edges = image.convolve(laplace)\n",
    "vizParams = {\n",
    "  'min': 0,\n",
    "  'max': 255,\n",
    "  'format': 'png'\n",
    "}\n",
    "zoom = 18\n",
    "\n",
    "map10 = build_map(lat, lon, zoom, vizParams, edges, 'Edge Detection')\n",
    "map10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b049b99fec94a46d20b9988d2997498044dc12560050df3afc669dc28cd1051f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
