{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3db34a80-4460-4b2c-b6d3-499ae7cc2a7d",
    "deepnote_cell_height": 1210.984375,
    "deepnote_cell_type": "markdown",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1648998935447,
    "owner_user_id": "658b2a16-1456-4994-b7e8-11257a829f64",
    "source_hash": "49fd145c",
    "tags": []
   },
   "source": [
    "# Lab 03 - Spectral Indices \n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab, we will work with the spectral characteristics in our data to visualize and extract insights that go beyond basic visual interpretation. We will work with the different spectral bands offered by Landsat 8 to find unique patterns that can help us solve problems and conduct analysis. By the end of this lab, you should be able to understand how to build and visualize existing indices, as well as construct your own, identify how different indices can help your use case, and understand the mechanism behind how they work. \n",
    "\n",
    "## Spectral Indices\n",
    "\n",
    "Spectroscopy is the study of how radiation is absorbed, reflected and emitted by different materials. While this discipline has its origins in chemistry and physics, we can utilize the same techniques to identify different land cover types from satellite data.  In the chart below, land cover types have unique spectral characteristics. Snow has a major peak at lower wavelengths and is near zero above 1.5 micrometer, whereas soil has very low reflectance at lower levels of wavelength but relatively strong and steady reflectance after ~0.75 micrometers. Spectral indices are built to leverage these unique characteristics and isolate specific types of land cover. \n",
    "\n",
    "Land covers are separable at different wavelengths. Vegetation curves (green) have high reflectance in the NIR range, where radiant energy is scattered by cell walls ([Bowker, 1985](http://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19850022138.pdf)) and low reflectance in the red range, where radiant energy is [absorbed by chlorophyll](https://en.wikipedia.org/wiki/Chlorophyll#/media/File:Chlorophyll_ab_spectra-en.svg). We can leverage this information to build indices that help us differentiate vegetation from urban areas. In the next few sections, we will cover several of the most important indices in use. \n",
    "\n",
    "![Land Cover Reflectance](https://github.com/ghidora77/03_GEE_Labs_DSPG/blob/main/im/im_03_01.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-565d752f-c570-48ae-8e4d-9e8f2b053c2c",
    "deepnote_cell_height": 354,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Important Indices \n",
    "\n",
    "#### Normalized Difference Vegetation Index (NDVI)\n",
    "\n",
    "The Normalized Difference Vegetation Index ([NDVI](https://developers.google.com/earth-engine/apidocs/ee-image-normalizeddifference)) has a [long history](https://en.wikipedia.org/wiki/Normalized_Difference_Vegetation_Index) in remote sensing, and is one of the most widely used measures. The typical formulation is:\n",
    "\n",
    "$$\\text{NDVI} = (\\text{NIR} - \\text{red}) / (\\text{NIR} + \\text{red})$$\n",
    "\n",
    "Where *NIR* refers to the near infrared band and *red* refers to the red peak in the visible spectrum.\n",
    "\n",
    "Because NDVI is a popular and well-known index, we can use the built-in functionality within Earth Engine `normalizedDifference()`to calculate NDVI. You can follow the steps below to build your own indices. \n",
    "\n",
    "First, build a baseline true color image around our region of interest, Niger. We will work with the Landsat 8 Collection 1 Tier 1 TOA Reflectance data from 2015, sort by cloud cover and extract the first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "00002-66b9b926-6f04-438c-8567-2e25df0419ea",
    "deepnote_cell_height": 189,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5465,
    "execution_start": 1648999061840,
    "source_hash": "e0a088c7"
   },
   "outputs": [],
   "source": [
    "#!pip install geemap\n",
    "\n",
    "import ee, geemap, pprint, folium\n",
    "#ee.Authenticate()\n",
    "\n",
    "def build_map(lat, lon, zoom, vizParams, image, name):\n",
    "    map = geemap.Map(center = [lat, lon], zoom = zoom)\n",
    "    map.addLayer(image, vizParams, name)\n",
    "    return map\n",
    "\n",
    "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
    "  map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
    "  folium.raster_layers.TileLayer(\n",
    "      tiles=map_id_dict['tile_fetcher'].url_format,\n",
    "      attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "      name=name,\n",
    "      overlay=True,\n",
    "      control=True\n",
    "  ).add_to(self)\n",
    "\n",
    "# Initialize the Earth Engine module.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "00003-b86653f0-d798-4356-b4b0-b8b60fda1625",
    "deepnote_cell_height": 594,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1736,
    "execution_start": 1648999067308,
    "source_hash": "e2c40ca2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9e1bc66c7c4916b5d436c102fdeac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[13.7, 2.6], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lat = 13.7; lon = 2.6\n",
    "zoom = 11\n",
    "image_collection_name = \"LANDSAT/LC08/C01/T1_TOA\"\n",
    "date_start = '2015-06-01'\n",
    "date_end = '2015-09-01'\n",
    "name = 'Landsat 8 TOA spectrum'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "\n",
    "bands = ['B4', 'B3', 'B2']\n",
    "\n",
    "vizParams = {\n",
    "    'bands': bands, \n",
    "    'min': 0, \n",
    "    'max': 0.3\n",
    "}\n",
    "\n",
    "# Define a map centered on southern Maine.\n",
    "map = build_map(lat, lon, zoom, vizParams, image, name)\n",
    "map.add_ee_layer(image, vizParams)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-0537d747-988a-4565-86ac-abb134bdd040",
    "deepnote_cell_height": 74,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Now that we have the true color baseline image, we can build the NDVI index and visualize it. For visualization, we are creating a custom palette, where low values trend towards white and high values trend towards green. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "00005-d950bf79-666a-478b-8cbf-c80d09cd6eea",
    "deepnote_cell_height": 288,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1907,
    "execution_start": 1648999069124,
    "source_hash": "9d7613ba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10e6148db0447f7bb31b575bf3fadcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[13.7, 2.6], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ndvi = image.normalizedDifference(['B5', 'B4']); \n",
    "vegPalette = ['white', 'green']; \n",
    "vizParams = {\n",
    "    'min': -1, \n",
    "    'max': 1,\n",
    "    'palette': vegPalette\n",
    "}\n",
    "\n",
    "map1 = build_map(lat, lon, zoom, vizParams, ndvi, name)\n",
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-53320485-348a-4c7d-80c6-bd673098d013",
    "deepnote_cell_height": 204,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Enhanced Vegetation Index (EVI) \n",
    "\n",
    "The Enhanced Vegetation Index (EVI) is designed to minimize saturation and background effects in NDVI ([Huete, 2002](http://www.sciencedirect.com/science/article/pii/S0034425702000962)). \n",
    "\n",
    "$$\\text{EVI} = 2.5 * (\\text{NIR} - \\text{red}) / (\\text{NIR} + 6 * \\text{red} - 7.5 * \\text{blue} + 1)$$\n",
    "\n",
    "Since it is not a normalized difference index, we need to build a unique [expression](https://developers.google.com/earth-engine/image_math#expressions) and then identify all of the different segments. Programmatically, bands are specifically referenced with the help of [an object](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Grammar_and_Types#Object_literals) that is passed as the second argument to `image.expression()` (everything within the curly brackets). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": "00008-10c3fffe-8dd1-431c-ac09-2dcd55293a0e",
    "deepnote_cell_height": 299,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1572,
    "execution_start": 1648999071039,
    "source_hash": "95736512"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc5b743e94e471181b179adb64a537a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[13.7, 2.6], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the expression\n",
    "exp = '2.5  * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))'\n",
    "evi = image.expression( exp, \n",
    "                            {\n",
    "                             'NIR': image.select('B5'),\n",
    "                             'RED': image.select('B4'),\n",
    "                             'BLUE': image.select('B2')\n",
    "                            }) \n",
    "\n",
    "map2 = build_map(lat, lon, zoom, vizParams, evi, name)\n",
    "map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-a49027c6-1326-434f-9b57-caf61763aef6",
    "deepnote_cell_height": 190,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Normalized Difference Water Index (NDWI)\n",
    "\n",
    "The Normalized Difference Water Index (NDWI) was developed by [Gao (1996)](http://www.sciencedirect.com/science/article/pii/S0034425796000673) as an index to identify the water content within vegetation. SWIR stands for short-wave infrared, which is the Landsat band 6.  This is not an exact implementation of NDWI, according to the [OLI spectral response](http://landsat.gsfc.nasa.gov/?p=5779), since OLI does not have a band in the right position (1.26 𝛍m) - but for our purposes, this is an approximation that does an acceptable job of identifying water content. \n",
    "\n",
    "$$\\text{NDWI} = (\\text{NIR} - \\text{SWIR})) / (\\text{NIR} + \\text{SWIR})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": "00011-c372264c-afed-4f68-8bdc-cf0246b0a524",
    "deepnote_cell_height": 299,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1670,
    "execution_start": 1648999072610,
    "source_hash": "5f71a306"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04154b324dee4653a5a7a9130544fb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[13.7, 2.6], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ndwi = image.normalizedDifference(['B5', 'B6']);  \n",
    "waterPalette = ['white', 'blue'];   \n",
    "\n",
    "vizParams = {\n",
    "    'min': -1, \n",
    "    'max': 1,\n",
    "    'palette': waterPalette\n",
    "}\n",
    "\n",
    "map3 = build_map(lat, lon, zoom, vizParams, ndwi, name)\n",
    "map3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-d57423c0-f6ea-454f-9554-8e3d7dc2a968",
    "deepnote_cell_height": 204,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Normalized Difference Water *Body* Index (NDWBI)\n",
    "\n",
    "The fact that two different NDWI indices were independently invented in 1996 complicates things. While the NDWI looks at water content within vegetation, the NDWBI is built to identify bodies of water (rivers, lakes, oceans). To distinguish, define the Normalized Difference Water *Body* Index (NDWBI) as the index described in [McFeeters (1996)](http://www.tandfonline.com/doi/abs/10.1080/01431169608948714#.VkThFHyrTlM):\n",
    "\n",
    "$$\\text{NDWBI} = (\\text{green} - \\text{NIR}) / (\\text{green} + \\text{NIR})$$\n",
    "\n",
    "As previously, implement NDWBI with `normalizedDifference()` and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": "00013-5487dc86-f49a-4376-b586-f4224f05e198",
    "deepnote_cell_height": 263,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2008,
    "execution_start": 1648999074280,
    "source_hash": "3bb2dc04"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e573a740f244b2bb4266fbf27c20de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[13.7, 2.6], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ndwbi = image.normalizedDifference(['B3', 'B5']);  \n",
    "vizParams = {\n",
    "    'min': -1, \n",
    "    'max': 0.5,\n",
    "    'palette': waterPalette\n",
    "}\n",
    "\n",
    "map4 = build_map(lat, lon, zoom, vizParams, ndwbi, name)\n",
    "map4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-58f4c5d4-c004-43e4-90b4-adc559d4a4e6",
    "deepnote_cell_height": 298,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "You can combine the code blocks to compare the actual values at different pixel locations. Use inspector to test out different land areas.\n",
    "\n",
    "\n",
    "#### Normalized Difference Bare Index (NDBI)\n",
    "\n",
    "The Normalized Difference Bare Index (NDBI) was developed by [Zha, 2003)](http://www.tandfonline.com/doi/abs/10.1080/01431160304987) to aid in the differentiation of urban areas by using a combination of the shortwave and near infrared. \n",
    "\n",
    "$$\\text{NDBI} = (\\text{SWIR} - \\text{NIR}) / (\\text{SWIR} + \\text{NIR})$$\n",
    "\n",
    "Note that NDBI is the negative of NDWI. Compute NDBI and display with a suitable palette. (Check [this reference](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array) to demystify the palette reversal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "00015-4405fb41-c068-41ee-9b67-33ab2b484f21",
    "deepnote_cell_height": 317,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1782,
    "execution_start": 1648999076292,
    "source_hash": "16e36938"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b15b7d756874e4b96079864870daf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[13.7, 2.6], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ndbi = image.normalizedDifference(['B6', 'B5']); \n",
    "# Reverse the water palette\n",
    "barePalette =  waterPalette.copy()\n",
    "barePalette.reverse() \n",
    "vizParams = {\n",
    "    'min': -1, \n",
    "    'max': 0.5,\n",
    "    'palette': barePalette\n",
    "}\n",
    "  \n",
    "map4 = build_map(lat, lon, zoom, vizParams, ndbi, name)\n",
    "map4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-cca2fe91-efe7-47db-90f8-240ec7a4bad5",
    "deepnote_cell_height": 154,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Burned Area Index (BAI) \n",
    "\n",
    "The Burned Area Index (BAI) was developed by [Chuvieco et al. (2002)](http://www.tandfonline.com/doi/abs/10.1080/01431160210153129) to assist in the delineation of burn scars and assessment of burn severity. It is based on maximizing the spectral characteristics of charcoal reflectance. To examine burn indices, load an image from 2013 showing the [Rim fire](https://en.wikipedia.org/wiki/Rim_Fire) in the Sierra Nevadas. We'll start by creating a true image of the area to see how well this index highlights the presence of wildfire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "00017-068ecc89-0ab5-4dc6-81df-eaa72449150b",
    "deepnote_cell_height": 605,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2017,
    "execution_start": 1648999078132,
    "source_hash": "6d972f7a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53de973e1024315a5509874157f0aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.85, -120.083], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(chil…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lat = 37.850; lon = -120.083; \n",
    "zoom = 11\n",
    "image_collection_name = \"LANDSAT/LC08/C01/T1_TOA\"\n",
    "date_start = '2013-08-17'\n",
    "date_end = '2013-09-27'\n",
    "name = 'Landsat  8 TOA spectrum in Blacksburg, VA'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "\n",
    "bands = ['B4', 'B3', 'B2']\n",
    "\n",
    "vizParams = {\n",
    "    'bands': bands, \n",
    "    'min': 0, \n",
    "    'max': 0.3\n",
    "}\n",
    "\n",
    "# Define a map centered on southern Maine.\n",
    "map5 = build_map(lat, lon, zoom, vizParams, image, name)\n",
    "map5.add_ee_layer(image, vizParams)\n",
    "map5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-8f65949d-7664-4b84-b6dd-bc3aa6cee86f",
    "deepnote_cell_height": 52,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Closely examine the true color display of this image. Can you spot where the fire occurred? If difficult, let's look at the burn index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": "00019-215d048e-f808-4bf1-b47c-c002026d98fe",
    "deepnote_cell_height": 461,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1579,
    "execution_start": 1648999080199,
    "source_hash": "582c6c18"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcba966306843bc93b492cd32efd694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.85, -120.083], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(chil…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Burn Index expression\n",
    "exp = '1.0  / ((0.1 - RED)**2 + (0.06 - NIR)**2)';\n",
    "bai = image.expression(exp, \n",
    "                       {\n",
    "                            'NIR': image.select('B5'), \n",
    "                            'RED': image.select('B4') \n",
    "                       }\n",
    "                      );\n",
    "                                \n",
    "burnPalette = ['green', 'blue', 'yellow', 'red'];\n",
    "\n",
    "vizParams = {\n",
    "    'min': 0, \n",
    "    'max': 400,\n",
    "    'palette': burnPalette\n",
    "}\n",
    "\n",
    "# Define a map centered on Northern California\n",
    "map6 = build_map(lat, lon, zoom, vizParams, bai, name)\n",
    "map6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-6f433684-c92e-4f2e-bc0f-8fd54e979e8b",
    "deepnote_cell_height": 248,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The charcoal burn area is now very evident. Being that Landsat has historical data and a wide array of sensors, this can be a powerful way to understand natural phenomena. \n",
    "\n",
    "\n",
    "\n",
    "#### Normalized Burn Ratio Thermal (NBRT)\n",
    "\n",
    "The Normalized Burn Ratio Thermal (NBRT) was developed based on the idea that burned land has low NIR reflectance (less vegetation), high SWIR reflectance (think ash), and high brightness temperature ([Holden et al. 2005](http://www.tandfonline.com/doi/abs/10.1080/01431160500239008)). Unlike the other indices, a lower NBRT means a higher likelihood of recent burn (for visualization, reverse the scale). This index can be used to diagnose the severity of wildfires (see [van Wagtendonk et al. 2004](http://www.sciencedirect.com/science/article/pii/S003442570400152X))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": "00021-24994c2c-1867-4daf-bc9b-54cabe96c2b6",
    "deepnote_cell_height": 407,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1641,
    "execution_start": 1648999081779,
    "source_hash": "7530f2b3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7816d50b5b410b82b77bdd2ffb8cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.85, -120.083], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(chil…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "   \n",
    "# Build Burn Index expression\n",
    "exp = '(NIR - 0.0001 * SWIR *  Temp) / (NIR + 0.0001 * SWIR * Temp)'\n",
    "nbrt = image.expression(exp, {\n",
    "        'NIR': image.select('B5'),   \n",
    "        'SWIR': image.select('B7'),   \n",
    "        'Temp': image.select('B11')  \n",
    "        });  \n",
    "vizParams = {\n",
    "    'min': 1, \n",
    "    'max': 0.9,\n",
    "    'palette': burnPalette\n",
    "}\n",
    "\n",
    "map7 = build_map(lat, lon, zoom, vizParams, nbrt, name)\n",
    "map7\n",
    "#Map.addLayer(nbrt, {min: 1, max: 0.9,  palette: burnPalette}, 'NBRT'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-41c3ee5b-1405-40f6-960b-53a3c5bc3f0c",
    "deepnote_cell_height": 226,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Normalized Difference Snow Index (NDSI)\n",
    "\n",
    "The Normalized Difference Snow Index (NDSI) was designed to estimate the amount of a pixel covered in snow ([Riggs et al. 1994](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=399618&tag=1)).\n",
    "\n",
    "$$\\text{NDSI} = (\\text{green} - \\text{SWIR}) /(\\text{green} + \\text{SWIR})$$\n",
    "\n",
    "Let's look at Aspen, Colorado and use Landsat 8 data in the winter. You can use the layer manager to turn on and off the snow layer to compare results with the true color image. How does it compare? Reference the spectral reflectance chart at the beginning of the lab and look at the profile for snow. You will see that it has a distinct profile. In the image below, it does a very good job of matching the true color image - valleys and roads that do not have snow on them are accurately shown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": "00023-f40989c5-f80f-4fd2-8542-3c7dda93dad0",
    "deepnote_cell_height": 767,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2154,
    "execution_start": 1648999083411,
    "source_hash": "c75fbac8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72944a02b6f94d2780142e029756367d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[39.19, -106.81], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lat = 39.19; lon = -106.81; \n",
    "zoom = 11\n",
    "image_collection_name = \"LANDSAT/LC08/C01/T1_TOA\"\n",
    "date_start = '2013-11-17'\n",
    "date_end = '2014-03-27'\n",
    "name = 'Snow'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "\n",
    "bands = ['B4', 'B3', 'B2']\n",
    "\n",
    "vizParams = {\n",
    "    'bands': bands, \n",
    "    'min': 0, \n",
    "    'max': 0.3\n",
    "}\n",
    "          \n",
    "ndsi = image.normalizedDifference(['B3', 'B6']);      \n",
    "snowPalette = ['red', 'green', 'blue', 'white'];   \n",
    "\n",
    "vizParams2 = {\n",
    "    'min': -0.5, \n",
    "    'max': 0.7,\n",
    "    'palette': snowPalette\n",
    "}\n",
    "\n",
    "# Define a map centered on southern Maine.\n",
    "map8 = build_map(lat, lon, zoom, vizParams, image, name)\n",
    "map8.add_ee_layer(ndsi, vizParams2)\n",
    "map8"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "edacfa2e-10e3-4b48-aa79-3b55c12175eb",
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
