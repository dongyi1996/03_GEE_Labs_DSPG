{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "908b4515-54db-4372-801d-ad36a7f9f2d9",
    "deepnote_cell_height": 316,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Image Processing\n",
    "\n",
    "## Overview\n",
    "In this lab, we will search for and visualize imagery in Google Earth Engine. We will discuss the difference between radiance and reflectance, make true color and false color composites from different bands and visually identify land cover types based on characteristics from the imagery. We will also discuss atmospheric effect on data collection by looking at the different data products available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-42da0771-64ba-442f-9359-4e09e155a142",
    "deepnote_cell_height": 177,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "####  Learning Outcomes\n",
    "\n",
    "- Extract single scenes from collections of images\n",
    "- Create and visualize different composites according\n",
    "- Use the Inspector tab to assess pixel values\n",
    "- Understand the difference between radiance and reflectance through visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-40135d1d-9acb-45e2-9d94-67c1ccc4f157",
    "deepnote_cell_height": 1027.984375,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Searching for Imagery\n",
    "\n",
    "The Landsat program is a joint program between NASA and the United States Geological Survey (USGS) that has launched a sequence of Earth observation satellites (Landsat 1-9).  Originating in 1984, the Landsat program provides the [longest continuous observation of the Earth's surface](https://www.youtube.com/embed/ZZx1xmNGcXI?list=PLD240BBC85537B9BE). Take the time to monitor some of the fascinating [timelapses](https://earthengine.google.com/timelapse/) using Landsat to showcase things like urban development, glacial retreat and deforestation.  \n",
    "\n",
    "Let's load a Landsat scene over our region of interest, inspect the units and plot the radiance. Specifically, use imagery from the Landsat 8, the most recent of the [sequence of Landsat satellites](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-8) (at the time of writing, Landsat 9 just launched and data is not yet available). \n",
    "\n",
    "To inspect a Landsat 8 image (also called a *scene*) in our region of interest (ROI), we can choose a point to center our map, filter the image collection to get a scene with few clouds, and display information about the image in the console.\n",
    "\n",
    "You can either scroll to the area on the map you're interested in and choose a point or use the search bar to find your location. Use the geometry tool to make a point in the country Niger (for these exercises we will include the point location in the script). \n",
    "\n",
    "![Using Search Bar](https://github.com/ghidora77/03_GEE_Labs_DSPG/blob/main/im/im_02_01a.png?raw=true)\n",
    "\n",
    "We will specifically be using USGS Landsat 8 Collection 1 Tier 1 Raw Scenes - if you read the documentation, the values refer to scaled, calibrated at-sensor radiance. Tier 1 means it is ready for analysis and is the highest quality imagery. There's quite a bit to learn about how the Landsat data is processed - if you will be working with Landsat extensively, take the time to read the Data Users [Handbook](https://www.usgs.gov/landsat-missions/landsat-8-data-users-handbook) for more information.\n",
    "\n",
    "We will filter the `ImageCollection` by date (year 2014) and location (to the ROI, which for this exercise is in Niger), sort by a metadata property included in the imagery called `CLOUD_COVER` and get the first image out of this sorted collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00003-c18e467b-e1fe-440f-959d-c10ed3705de3",
    "deepnote_cell_height": 261,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5673,
    "execution_start": 1648998873287,
    "source_hash": "4c7ed9a4"
   },
   "outputs": [],
   "source": [
    "#!pip install geemap\n",
    "\n",
    "import ee, geemap, pprint, folium\n",
    "#ee.Authenticate()\n",
    "\n",
    "def build_map(lat, lon, zoom, vizParams, image, name):\n",
    "    map = geemap.Map(center = [lat, lon], zoom = zoom)\n",
    "    map.addLayer(image, vizParams, name)\n",
    "    return map\n",
    "\n",
    "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
    "  map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
    "  folium.raster_layers.TileLayer(\n",
    "      tiles=map_id_dict['tile_fetcher'].url_format,\n",
    "      attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "      name=name,\n",
    "      overlay=True,\n",
    "      control=True\n",
    "  ).add_to(self)\n",
    "\n",
    "# Initialize the Earth Engine module.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00004-8d166600-7f1a-4100-be59-99abed5fd77d",
    "deepnote_cell_height": 653,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1955,
    "execution_start": 1648998878966,
    "source_hash": "bd106899"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9adc67bfa14b84b5eca17273176ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[13.7, 2.6], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lat = 13.7; lon = 2.6\n",
    "zoom = 11\n",
    "image_collection_name = \"LANDSAT/LC08/C01/T1_TOA\"\n",
    "date_start = '2014-01-01'\n",
    "date_end = '2014-12-31'\n",
    "name = 'Landsat'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "\n",
    "bands = ['B4', 'B3', 'B2']\n",
    "\n",
    "vizParams = {\n",
    "    'bands': bands, \n",
    "    'min': 0, \n",
    "    'max': 0.4\n",
    "}\n",
    "\n",
    "map = build_map(lat, lon, zoom, vizParams, image, name)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-425caeea-acd1-494d-b1a2-606271149f06",
    "deepnote_cell_height": 172,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The variable `image` now stores a reference to an object of type `ee.Image`. In other words, we have taken the image collection and reduced it down to a single image, which is now ready for visualization. \n",
    "\n",
    "Before we visualize the data, go to the console and click on the dropdown. \n",
    "\n",
    "![Image Properties](https://github.com/ghidora77/03_GEE_Labs_DSPG/blob/main/im/im_02_01b.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-15381788-fefd-44c4-80cc-040eeb6f710b",
    "deepnote_cell_height": 198,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "Expand and explore the image by clicking the triangle next to the image name to see more information stored in that object. Specifically, expand `properties` and inspect the long list of metadata items stored as properties of the image. This is where the `CLOUD_COVER` property you just used is stored.\n",
    "\n",
    "There are band specific coefficients (`RADIANCE_ADD_*`, `RADIANCE_MULT_*` where \\* is a band name) in the metadata for converting from the digital number (DN) stored by the image into physical units of radiance. These coefficients will be useful in later exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-426173b0-61f9-480f-bcfa-63668ff617b0",
    "deepnote_cell_height": 240,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Visualizing Landsat Imagery\n",
    "\n",
    "Recall from the last lab that Landsat 8 measures radiance in multiple spectral bands. A common way to visualize images is to set the red band to display in red, the green band to display in green and the blue band to display in blue - just as you would create a normal photograph. This means trying to match the [spectral response of the instrument](http://landsat.gsfc.nasa.gov/?p=5779) to the spectral response of the photoreceptors in the human eye. It's not a perfect match but this is called a *true-color* image. When the display bands don't match human visual perception (as we will see later), the visualization is called a *false-color composite*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-c27ffb9d-1a61-46d0-98af-8bcdeebcc3be",
    "deepnote_cell_height": 198,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### True Color Composite\n",
    "\n",
    "To build a true color image we are building a variable called `trueColor`  that selects the red / green / blue bands in order and includes the min and max value to account for the appropriate radiometric resolution - this piece can be tricky, as it is unique for each dataset you work with. You can find the band names and min-max values to use from the dataset documentation page, but a great starting point is to use the 'code example' snippet for each dataset, which will set up the visualization parameters for you.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00009-daa5b7c6-5620-46ba-9096-6aaeb018bd20",
    "deepnote_cell_height": 635,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1962,
    "execution_start": 1648998880966,
    "source_hash": "2e97cddf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549c46a3fbcd4d199ac55e9a40d6ac2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[13.7, 2.6], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zoom = 11\n",
    "image_collection_name = \"LANDSAT/LC08/C01/T1\"\n",
    "date_start = '2014-01-01'\n",
    "date_end = '2014-12-31'\n",
    "name = 'Landsat - True Color'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "\n",
    "bands = ['B4', 'B3', 'B2']\n",
    "\n",
    "vizParams = {\n",
    "    'bands': bands, \n",
    "    'min': 4000, \n",
    "    'max': 18000\n",
    "}\n",
    "\n",
    "map1 = build_map(lat, lon, zoom, vizParams, image, name)\n",
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-82aa0b60-1fc9-4245-be24-e3cb8b8968f0",
    "deepnote_cell_height": 162,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "There is more than one way to discover the appropriate min and max values to display. Try going to the **Inspector** tab and clicking somewhere on the map. The value in each band, in the pixel where you clicked, is displayed as a list in the console. Try clicking on dark and bright objects to get a sense of the range of pixel values. Also, [layer manager](https://developers.google.com/earth-engine/playground#layer-manager) in the upper right of the map display lets you automatically compute a linear stretch based on the pixels in the map display. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-332071b7-5325-4394-841c-b3e9bc122417",
    "deepnote_cell_height": 242,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### False Color Composite\n",
    "\n",
    "Let's do the same thing, but this time we will build a false-color composite. This particular set of bands results in a *color-IR composite* because the near infra-red (NIR) band is set to red. As you inspect the map, look at the pixel values and try to find relationships between the NIR band and different land types. Using false color composites is a very common and powerful method of identifying land characteristics by leveraging the power of signals outside of the visible realm. Mining engineers commonly use hyperspectral data to pinpoint composites with unique signatures, and urban growth researchers commonly use the infrared band to pinpoint roads and urban areas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00012-ff1f158c-0dea-44e2-844b-a2b6d18199e2",
    "deepnote_cell_height": 635,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1668,
    "execution_start": 1648998882610,
    "source_hash": "7e054a1c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5f0b6cc36946eabadd112e5e73e1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[13.7, 2.6], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zoom = 11\n",
    "image_collection_name = \"LANDSAT/LC08/C01/T1\"\n",
    "date_start = '2014-01-01'\n",
    "date_end = '2014-12-31'\n",
    "name = 'Landsat - False Color'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "\n",
    "bands = ['B5', 'B4', 'B3']\n",
    "\n",
    "vizParams = {\n",
    "    'bands': bands, \n",
    "    'min': 6000,\n",
    "    'max': 20000\n",
    "}\n",
    "\n",
    "map2 = build_map(lat, lon, zoom, vizParams, image, name)\n",
    "map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-937ec8df-4680-458b-bb6d-c3ce95d4b655",
    "deepnote_cell_height": 172,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Read through the Landsat data documentation and try playing with different band combinations, min and max values to build different visualizations. \n",
    "\n",
    "**Unique Feature**: You can include multiple visualization parameters in your script and toggle the layers on and off with the layer manager for easy comparison. \n",
    "\n",
    "![Layer Manager](https://github.com/ghidora77/03_GEE_Labs_DSPG/blob/main/im/im_02_03.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-a06749a2-7b23-42fd-917b-78cce329e032",
    "deepnote_cell_height": 530,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## At-Sensor Radiance\n",
    "\n",
    "The image data you have used so far is stored as a digital number that measures the intensity within the bit range - if data is collected in an 8-bit system, 255 would be very high intensity and 0 will be no intensity. To convert each digital number into a physical unit (at-sensor [radiance](https://en.wikipedia.org/wiki/Radiance) in Watts/m2/sr/𝝁m), we can use a linear equation:\n",
    "\n",
    "$$\n",
    "L_{\\lambda} = a_{\\lambda} * DN_{\\lambda} + b_{\\lambda}  \\qquad\n",
    "$$\n",
    "\n",
    "\n",
    "Note that every term is indexed by lamda ($\\lambda$, the symbol for wavelength) because the coefficients are different in each band. See [Chander et al. (2009)](http://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on this linear transformation between DN and radiance. In this exercise, you will generate a radiance image and examine the differences in radiance from different targets.\n",
    "\n",
    "Earth Engine provides built-in functions for converting Landsat imagery to radiance in Watts/m2/sr/𝝁m. It will automatically reference the metadata values for each band and apply the equation for you, saving you the trouble of conducing numerous calculations.\n",
    "\n",
    "This code applies the transformation to a subset of bands (specified by a list of band names) obtained from the image using select(). That is to facilitate interpretation of the radiance spectrum by removing the panchromatic band ('B8'), an atmospheric absorption band ('B9') and the QA band ('BQA'). \n",
    "\n",
    "Note that the visualization parameters are different to account for the radiance units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00015-b8872cd0-fa5c-4331-86e6-e472f141ce30",
    "deepnote_cell_height": 707,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2052,
    "execution_start": 1648998884300,
    "source_hash": "58b641"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a44f861c7a1456dbe2be157c9165d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[13.7, 2.6], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zoom = 11\n",
    "image_collection_name = \"LANDSAT/LC08/C01/T1\"\n",
    "date_start = '2014-01-01'\n",
    "date_end = '2014-12-31'\n",
    "name = 'Landsat'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "\n",
    "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11']\n",
    "\n",
    "dnImage = image.select(bands)\n",
    "\n",
    "radiance =  ee.Algorithms.Landsat.calibratedRadiance(dnImage)\n",
    "\n",
    "vizParams = {\n",
    "    'bands': ['B5', 'B4', 'B3'], \n",
    "    'min': 50, \n",
    "    'max': 150\n",
    "}\n",
    "\n",
    "map3 = build_map(lat, lon, zoom, vizParams, image, name)\n",
    "map3.add_ee_layer(radiance, vizParams)\n",
    "map3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-223fadd8-8346-4a79-b5f7-f271be64c1ed",
    "deepnote_cell_height": 242,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Examine the radiance image by using **Inspector** and clicking different land cover types on the map near Blacksburg, VA. Click the chart icon (![Chart](./im/im_02_04.png)) in the console to get a bar chart of the different radiance values for each pixel. If the shape of the chart resembles Figure 1, that's because the radiance (in bands 1-7) is mostly reflected solar irradiance. The radiance detected in bands 10-11 is thermal, and is *emitted* (not reflected) from the surface.\n",
    "\n",
    "![Electromagnetic Spectrum](https://github.com/ghidora77/03_GEE_Labs_DSPG/blob/main/im/im_02_05.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-72666b76-6ed3-4ca9-8770-005c188c0608",
    "deepnote_cell_height": 684,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Top-of-Atmosphere (TOA) Reflectance \n",
    "\n",
    "The Landsat sensor is in orbit approximately 700 kilometers above Earth. If we are focused on the imagery of remote sensing (as opposed to studying something like atmospheric conditions or ambient temperature), then we want to find insights about the surface of the earth. To understand the way we calculate information, there are three main components.\n",
    "\n",
    "Digital Number (DN) is a value that is associated with each pixel - it is generic (in that it is an intensity value dependent upon the bit range), and it allows you to visualize the image where all pixels are in context. In most cases, DN is appropriate for analysis, image processing, machine learning, etc.\n",
    "\n",
    "Radiance is the radiation that collected by a sensor - this includes radiation from the surface of Earth, radiation scattered by clouds, position of the sun relative to the Earth and sensor, etc. In general, we want to correct radiance values and convert to reflectance. \n",
    "\n",
    "Reflectance is the ratio (unitless)  of energy from the sun to the energy reflected off Earth's surface. In fact, it's more complicated than this because radiance is a directional quantity, but this definition captures the basic idea  We can identify materials based on their reflectance spectra. Because this ratio is computed using whatever radiance the sensor measures (which may contain all sorts of atmospheric effects), it's called *at-sensor* or *top-of-atmosphere* (TOA) reflectance. \n",
    "\n",
    "Top of Atmosphere reflectance is the reflectance that includes the radiation from earth's surface and radiation from earth's atmosphere. \n",
    "\n",
    "Let's examine the spectra for TOA Landsat data. To get TOA data for Landsat, we can do the transformation using the built-in functions created by Earth Engine. We will be using 'USGS Landsat 8 Collection 1 Tier 1 TOA Reflectance' ImageCollection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00019-ffc7b018-d316-47a0-959e-55bcd85934bf",
    "deepnote_cell_height": 779,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2064,
    "execution_start": 1648998886393,
    "source_hash": "3cffcee0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160e2d53c2244e6bb42f9f323c54ae14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[13.7, 2.6], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zoom = 11\n",
    "image_collection_name = \"LANDSAT/LC08/C01/T1_TOA\"\n",
    "date_start = '2014-01-01'\n",
    "date_end = '2014-12-31'\n",
    "name = 'Landsat  8 TOA spectrum in Blacksburg, VA'\n",
    "point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection(image_collection_name)\n",
    "         .filterBounds(point)\n",
    "         .filterDate(date_start, date_end)\n",
    "         .sort('CLOUD_COVER')\n",
    "         .first()\n",
    ")\n",
    "\n",
    "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11']\n",
    "reflectiveBands = bands[0:8]; \n",
    "# See http://landsat.usgs.gov/band_designations_landsat_satellites.php  \n",
    "wavelengths = [0.44, 0.48, 0.56, 0.65, 0.86, 1.61, 2.2]\n",
    "\n",
    "reflectanceImage =  image.select(reflectiveBands);  \n",
    "\n",
    "radiance =  ee.Algorithms.Landsat.calibratedRadiance(dnImage)\n",
    "\n",
    "vizParams = {\n",
    "    'bands': ['B5', 'B4', 'B3'], \n",
    "    'min': 0.1, \n",
    "    'max': 0.6\n",
    "}\n",
    "\n",
    "map4 = build_map(lat, lon, zoom, vizParams, image, name)\n",
    "map4.add_ee_layer(reflectanceImage, vizParams)\n",
    "map4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-a2836a3a-f675-40cb-9bcb-53368006aba1",
    "deepnote_cell_height": 526,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Since reflectance is a unitless ratio in [0, 1], change the visualization parameters to correctly display the TOA data:\n",
    "\n",
    "Using **Inspector**, click several locations on the map and examine the resultant spectra. It should be apparent, especially if you chart the spectra, that the scale of pixel values in different bands is drastically different. Specifically, bands 10-11 are not in [0, 1].  The reason is that these are thermal bands, and are converted to brightness temperature, in Kelvin, as part of the TOA conversion. Very little radiance is reflected in this wavelength range; most is emitted from the Earth's surface. That emitted radiance can be used to estimate [brightness temperature](https://en.wikipedia.org/wiki/Brightness_temperature) using the inverted [Planck equation](https://en.wikipedia.org/wiki/Planck's_law). Examine the temperature of various locations. Now add this command to the TOA image before adding it to the map to get only bands 1-9 \n",
    "\n",
    "* ` .select('B([0-9])')`\n",
    "\n",
    "To make plots of reflectance, select the reflective bands from the TOA image and use the Earth Engine [charting API](https://developers.google.com/earth-engine/charts). \n",
    "\n",
    "There are several new methods in this code. The `slice()` method gets entries in a list based on starting and ending indices. Search the docs (on the **Docs** tab) for 'slice' to find other places this method can be used. Construction of the chart is handled by an object of customization parameters ([learn more about customizing charts](https://developers.google.com/earth-engine/charts_image_histogram)) passed to [Chart.image.regions()](https://developers.google.com/earth-engine/charts_image_regions). Customizing charts within GEE can be difficult, so spend time modifying the characteristics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-92d77b3d-8369-402d-b9b3-804ea056f8f4",
    "deepnote_cell_height": 408,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Surface Reflectance \n",
    "\n",
    "The ratio of upward radiance *at the Earth's surface* to downward radiance *at the Earth's surface* is called surface reflectance. Unlike TOA reflectance, in which this information is collected at the sensor, the radiances at the Earth's surface have been affected by the atmosphere. both the inbound and outbound radiance from the sun is affected by its path through the atmosphere to the sensor. Unravelling those effects is called atmospheric correction (\"compensation\" is probably a more accurate term) and is beyond our scope of this lab. However, most satellite imagery providers complete this correction for the consumers. While you could use the raw scenes directly, if your goal is conduct analysis quickly and effectively, using the corrected Surface Reflectance image collections are quite beneficial and will save you quite a bit of time."
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "fe256bdb-ee82-4e1a-af04-2cce3be633f7",
  "interpreter": {
   "hash": "ec9e24bde1833ef0ef93e4cf9cecf27c680e00c5d9cebee87bbc6a68c9a6acfb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('geospatial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
